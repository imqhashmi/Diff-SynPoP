{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 7841693,
     "sourceType": "datasetVersion",
     "datasetId": 4428879
    }
   ],
   "dockerImageVersionId": 30648,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "# appending the system path to run the file on kaggle\n",
    "# not required if you are running it locally\n",
    "sys.path.insert(1, '/kaggle/input/diffspop/Diff-SynPoP')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import plotly as py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# imporint InputData and InputCrossTables for processing UK census data files\n",
    "import InputData as ID\n",
    "import InputCrossTables as ICT\n",
    "\n",
    "from torch.nn import init\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import ExponentialLR"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-03-14T12:45:10.891554Z",
     "iopub.execute_input": "2024-03-14T12:45:10.891839Z",
     "iopub.status.idle": "2024-03-14T12:45:22.172847Z",
     "shell.execute_reply.started": "2024-03-14T12:45:10.891816Z",
     "shell.execute_reply": "2024-03-14T12:45:22.171653Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Imran\\\\Desktop\\\\Oxford\\\\Code\\\\SyntheticPopulation\\\\Diff-SynPoP\\\\input/diffspop/Diff-SynPoP\\\\Census_2011_MSOA\\\\individual\\\\Age_5yrs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01moptim\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# imporint InputData and InputCrossTables for processing UK census data files\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mInputData\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mID\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mInputCrossTables\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mICT\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m init\n",
      "File \u001B[1;32m~\\Desktop\\Oxford\\Code\\SyntheticPopulation\\Diff-SynPoP\\Jupyter\\InputData.py:113\u001B[0m\n\u001B[0;32m    111\u001B[0m oxford_areas \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005921\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005922\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005923\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005924\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005925\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005926\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005927\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005928\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005929\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005930\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005931\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005932\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005933\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005934\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005935\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005936\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005937\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005938\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005939\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005940\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005941\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005942\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005943\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005944\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005945\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005946\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005947\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005948\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005949\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005950\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005951\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005952\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005953\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005954\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005955\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005956\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005957\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005958\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005959\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005960\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005961\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005962\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005963\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005964\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005965\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005966\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005967\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005968\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005969\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005970\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005971\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005972\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005973\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005974\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005975\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005976\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005977\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005978\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005979\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005980\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005981\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005982\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005983\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005984\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005985\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005986\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005987\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005988\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005991\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005992\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02006886\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005993\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005994\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005995\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005996\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005997\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005998\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02005999\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02006000\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02006001\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02006002\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02006003\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02006004\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02006005\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02006006\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mE02006007\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m    112\u001B[0m \u001B[38;5;66;03m# Read census data\u001B[39;00m\n\u001B[1;32m--> 113\u001B[0m age5ydf \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mCensus_2011_MSOA\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mindividual\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mAge_5yrs.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    114\u001B[0m age5ydf \u001B[38;5;241m=\u001B[39m age5ydf[age5ydf[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgeography code\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39misin(oxford_areas)]\n\u001B[0;32m    116\u001B[0m sexdf \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCensus_2011_MSOA\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindividual\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSex.csv\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    935\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    936\u001B[0m     dialect,\n\u001B[0;32m    937\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    944\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m    945\u001B[0m )\n\u001B[0;32m    946\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 948\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    608\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    610\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 611\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    613\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    614\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1445\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1447\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1448\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1703\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1704\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1705\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1706\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1711\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1712\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1713\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1714\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1715\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1716\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:863\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    859\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    860\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    861\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    862\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 863\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    869\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    871\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    872\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Imran\\\\Desktop\\\\Oxford\\\\Code\\\\SyntheticPopulation\\\\Diff-SynPoP\\\\input/diffspop/Diff-SynPoP\\\\Census_2011_MSOA\\\\individual\\\\Age_5yrs.csv'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class FFNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        super(FFNetwork, self).__init__()\n",
    "        layers = []\n",
    "        in_dims = [input_dim] + hidden_dims[:-1] # these are the input dimensions for each layer\n",
    "        for in_dim, out_dim in zip(in_dims, hidden_dims):\n",
    "            layers.append(nn.Linear(in_dim, out_dim)) # a linear layer\n",
    "            layers.append(nn.BatchNorm1d(out_dim)) # a batch normalization layer (helps with quicker covnergence)\n",
    "            layers.append(nn.ReLU()) # non-linearity / activation function (ReLU performed the best among others)\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return self.output_layer(x)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:45:22.174852Z",
     "iopub.execute_input": "2024-03-14T12:45:22.175189Z",
     "iopub.status.idle": "2024-03-14T12:45:22.183440Z",
     "shell.execute_reply.started": "2024-03-14T12:45:22.175160Z",
     "shell.execute_reply": "2024-03-14T12:45:22.182361Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # checking to see if a cuda device is available \n",
    "path = os.path.join(os.path.dirname(os.getcwd()), 'Diff-SynPoP')\n",
    "\n",
    "#MSOA\n",
    "area = 'E02005924' # geography code for one of the oxford areas (selected for this work)\n",
    "total = ID.get_total(ID.age5ydf, area) # getting the total number of individuals in our MSOA\n",
    "\n",
    "# getting the distributions of individual attributes in the selected MSOA\n",
    "# saving the extracted distributions into respective dictionaries\n",
    "sex_dict = ID.getdictionary(ID.sexdf, area) # sex\n",
    "age_dict = ID.getdictionary(ID.age5ydf, area) # age\n",
    "ethnic_dict = ID.getdictionary(ID.ethnicdf, area) # ethnicity\n",
    "religion_dict = ID.getdictionary(ID.religiondf, area) # religion\n",
    "marital_dict = ID.getdictionary(ID.maritaldf, area) # marital status\n",
    "qual_dict = ID.getdictionary(ID.qualdf, area) # highest qualification level\n",
    "\n",
    "# getting the length (number of classes) for each attribute \n",
    "category_lengths = {\n",
    "    'sex': len(sex_dict),\n",
    "    'age': len(age_dict),\n",
    "    'ethnicity': len(ethnic_dict),\n",
    "    'religion': len(religion_dict),\n",
    "    'marital': len(marital_dict),\n",
    "    'qual': len(qual_dict)\n",
    "}\n",
    "\n",
    "cross_table1 = ICT.getdictionary(ICT.ethnic_by_sex_by_age, area)\n",
    "cross_table2 = ICT.getdictionary(ICT.religion_by_sex_by_age, area)\n",
    "cross_table3 = ICT.getdictionary(ICT.marital_by_sex_by_age, area)\n",
    "cross_table4 = ICT.getdictionary(ICT.qualification_by_sex_by_age, area)\n",
    "\n",
    "cross_table_tensor1 = torch.tensor(list(cross_table1.values()), dtype=torch.float32).to(device).cuda()\n",
    "cross_table_tensor2 = torch.tensor(list(cross_table2.values()), dtype=torch.float32).to(device).cuda()\n",
    "cross_table_tensor3 = torch.tensor(list(cross_table3.values()), dtype=torch.float32).to(device).cuda()\n",
    "cross_table_tensor4 = torch.tensor(list(cross_table4.values()), dtype=torch.float32).to(device).cuda()\n",
    "\n",
    "# instantiating networks for each characteristic\n",
    "input_dim = sum(len(d.keys()) for d in [sex_dict, age_dict, ethnic_dict, religion_dict, marital_dict, qual_dict])\n",
    "hidden_dims = [64, 32]\n",
    "\n",
    "sex_net = FFNetwork(input_dim, hidden_dims, len(sex_dict)).to(device).cuda()\n",
    "age_net = FFNetwork(input_dim, hidden_dims, len(age_dict)).to(device).cuda()\n",
    "ethnic_net = FFNetwork(input_dim, hidden_dims, len(ethnic_dict)).to(device).cuda()\n",
    "relgion_net = FFNetwork(input_dim, hidden_dims, len(religion_dict)).to(device).cuda()\n",
    "marital_net = FFNetwork(input_dim, hidden_dims, len(marital_dict)).to(device).cuda()\n",
    "qual_net = FFNetwork(input_dim, hidden_dims, len(qual_dict)).to(device).cuda()\n",
    "\n",
    "# input for the networks\n",
    "# input_tensor = torch.randn(total, input_dim).to(device)  # Random noise as input, adjust as necessary\n",
    "\n",
    "input_tensor = torch.empty(total, input_dim).to(device)\n",
    "init.kaiming_normal_(input_tensor)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:45:22.184956Z",
     "iopub.execute_input": "2024-03-14T12:45:22.185375Z",
     "iopub.status.idle": "2024-03-14T12:45:23.193922Z",
     "shell.execute_reply.started": "2024-03-14T12:45:22.185330Z",
     "shell.execute_reply": "2024-03-14T12:45:23.192839Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# defining the Gumbel-Softmax function\n",
    "def gumbel_softmax_sample(logits, temperature=0.5):\n",
    "    gumbel_noise = -torch.log(-torch.log(torch.rand(logits.shape, device=device)))\n",
    "    y = logits + gumbel_noise\n",
    "    return torch.nn.functional.softmax(y / temperature, dim=-1)\n",
    "\n",
    "def generate_population(input_tensor, temperature=0.5):\n",
    "    sex_logits = sex_net(input_tensor)\n",
    "    age_logits = age_net(input_tensor)\n",
    "    ethnicity_logits = ethnic_net(input_tensor)\n",
    "    relgion_logits = relgion_net(input_tensor)\n",
    "    marital_logits = marital_net(input_tensor)\n",
    "    qual_logits = qual_net(input_tensor)\n",
    "    \n",
    "    sex = gumbel_softmax_sample(sex_logits, temperature)\n",
    "    age = gumbel_softmax_sample(age_logits, temperature)\n",
    "    ethnicity = gumbel_softmax_sample(ethnicity_logits, temperature)\n",
    "    relgion = gumbel_softmax_sample(relgion_logits, temperature)\n",
    "    marital = gumbel_softmax_sample(marital_logits, temperature)\n",
    "    qual = gumbel_softmax_sample(qual_logits, temperature)\n",
    "\n",
    "    return torch.cat([sex, age, ethnicity, relgion, marital, qual], dim=-1)\n",
    "\n",
    "def aggregate(encoded_tensor, cross_table, category_dicts):\n",
    "    # calculating split sizes based on category dictionaries\n",
    "    split_sizes = [len(cat_dict) for cat_dict in category_dicts]\n",
    "    # making sure that tensor dimension matches the total category count\n",
    "    if encoded_tensor.size(1) != sum(split_sizes):\n",
    "        raise ValueError(\"Size mismatch between encoded_tensor and category_dicts\")\n",
    "\n",
    "    # splitting the tensor into category-specific probabilities\n",
    "    category_probs = torch.split(encoded_tensor, split_sizes, dim=1)\n",
    "\n",
    "    # initializing the aggregated tensor\n",
    "    aggregated_tensor = torch.zeros(len(cross_table.keys()), device=device)\n",
    "\n",
    "    # aggregating the tensor based on the cross table\n",
    "    for i, key in enumerate(cross_table.keys()):\n",
    "        category_keys = key.split(' ')\n",
    "        expected_count = torch.ones(encoded_tensor.size(0), device=device) # Initialize as a vector\n",
    "\n",
    "        # multiplying probabilities across each category\n",
    "        for cat_index, cat_key in enumerate(category_keys):\n",
    "            category_index = list(category_dicts[cat_index].keys()).index(cat_key)\n",
    "            expected_count *= category_probs[cat_index][:, category_index]\n",
    "\n",
    "        # aggregating the expected counts\n",
    "        aggregated_tensor[i] = torch.sum(expected_count)\n",
    "    return aggregated_tensor\n",
    "\n",
    "def decode_tensor(encoded_tensor, category_dicts):\n",
    "    # calculating the split sizes from the category dictionaries\n",
    "    split_sizes = [len(cat_dict) for cat_dict in category_dicts]\n",
    "\n",
    "    # dynamic tensor splitting\n",
    "    category_encoded_tensors = torch.split(encoded_tensor, split_sizes, dim=1)\n",
    "\n",
    "    # decoding each category\n",
    "    decoded_categories = []\n",
    "    for cat_tensor, cat_dict in zip(category_encoded_tensors, category_dicts):\n",
    "        cat_labels = list(cat_dict.keys())\n",
    "        decoded_cat = [cat_labels[torch.argmax(ct).item()] for ct in cat_tensor]\n",
    "        decoded_categories.append(decoded_cat)\n",
    "\n",
    "    # combining the decoded categories\n",
    "    return list(zip(*decoded_categories))\n",
    "\n",
    "def keep_categories(encoded_tensor, category_lengths, categories_to_keep):\n",
    "    # calculating the indices for the categories to be kept\n",
    "    keep_indices = []\n",
    "    current_index = 0\n",
    "    for category, length in category_lengths.items():\n",
    "        if category in categories_to_keep:\n",
    "            indices = torch.arange(start=current_index, end=current_index + length, device=encoded_tensor.device)\n",
    "            keep_indices.append(indices)\n",
    "        current_index += length\n",
    "\n",
    "    # concatenating all keep_indices and using them to index the tensor\n",
    "    keep_indices = torch.cat(keep_indices, dim=0)\n",
    "    kept_tensor = encoded_tensor[:, keep_indices]\n",
    "    return kept_tensor\n",
    "\n",
    "def plot(target, computed, cross_table, name):\n",
    "    accuracy = rmse_accuracy(target.cpu(), computed.cpu())\n",
    "    # creating bar plots for both dictionaries\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(cross_table.keys()),\n",
    "        y=list(target.tolist()),\n",
    "        name='Target',\n",
    "        marker_color='#636EFA'\n",
    "    ))\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(cross_table.keys()),\n",
    "        y=list(computed.tolist()),\n",
    "        name='Computed',\n",
    "        marker_color='#EF553B'\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title= name + ' [' + \"RMSE:\" + str(accuracy) + ']',\n",
    "        xaxis_tickangle=-90,\n",
    "        xaxis_title='Categories',\n",
    "        yaxis_title='Counts',\n",
    "        barmode='group',\n",
    "        bargap=0.5,\n",
    "        width=9000\n",
    "    )\n",
    "    # saving plot\n",
    "    #py.offline.plot(fig, filename= path + '/plots/' + str(name) + '.html')\n",
    "    # showing plot\n",
    "    fig.show()\n",
    "\n",
    "# encoded_population = generate_population(input_tensor).cuda()\n",
    "# records = decode_tensor(encoded_population, [sex_dict, age_dict, ethnic_dict, religion_dict, marital_dict, qual_dict])\n",
    "# print(records)\n",
    "# categories_to_keep = ['sex', 'age', 'marital']  # Categories to keep\n",
    "# kept_tensor = keep_categories(encoded_population, category_lengths, categories_to_keep)\n",
    "# aggregated_tensor = aggregate(kept_tensor, cross_table3, [sex_dict, age_dict, marital_dict])\n",
    "\n",
    "def rmse_accuracy(computed_tensor, target_tensor):\n",
    "    mse = torch.mean((target_tensor - computed_tensor) ** 2)\n",
    "    rmse = torch.sqrt(mse)\n",
    "    max_possible_error = torch.sqrt(torch.sum(target_tensor ** 2))\n",
    "    accuracy = 1 - (rmse / max_possible_error)\n",
    "    return accuracy.item()\n",
    "\n",
    "def rmse_loss(aggregated_tensor, target_tensor):\n",
    "    return torch.sqrt(torch.mean((aggregated_tensor - target_tensor) ** 2))\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # nn.init.xavier_uniform_(m.weight)\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        nn.init.zeros_(m.bias)\n",
    "        \n",
    "def combined_rmse_loss(aggregated_tensor1, aggregated_tensor2, aggregated_tensor3, aggregated_tensor4, target_tensor1, target_tensor2, target_tensor3, target_tensor4):\n",
    "    # concatenating the target and computed tensors along the characteristic dimension (dim=1)\n",
    "    concatenated_tensor = torch.cat([target_tensor1, target_tensor2, target_tensor3, target_tensor4])\n",
    "    aggregated_cat_tensor = torch.cat([aggregated_tensor1, aggregated_tensor2, aggregated_tensor3, aggregated_tensor4])\n",
    "    # calculating RMSE loss on the concatenated tensor\n",
    "    loss = torch.sqrt(torch.mean((aggregated_cat_tensor - concatenated_tensor) ** 2))\n",
    "    return loss"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:45:23.196372Z",
     "iopub.execute_input": "2024-03-14T12:45:23.196738Z",
     "iopub.status.idle": "2024-03-14T12:45:23.224994Z",
     "shell.execute_reply.started": "2024-03-14T12:45:23.196709Z",
     "shell.execute_reply": "2024-03-14T12:45:23.224221Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "generated_population = generate_population(input_tensor)\n",
    "records = decode_tensor(generated_population, [sex_dict, age_dict, ethnic_dict, religion_dict, marital_dict, qual_dict])\n",
    "df = pd.DataFrame(records, columns=['sex', 'age', 'ethnicity', 'religion', 'marital', 'qualification'])\n",
    "print(df)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:45:23.226501Z",
     "iopub.execute_input": "2024-03-14T12:45:23.226853Z",
     "iopub.status.idle": "2024-03-14T12:45:26.205804Z",
     "shell.execute_reply.started": "2024-03-14T12:45:23.226828Z",
     "shell.execute_reply": "2024-03-14T12:45:26.204621Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loss_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "# recording execution start time\n",
    "start = time.time()\n",
    "\n",
    "# training loop\n",
    "optimizer = torch.optim.Adam([{'params': sex_net.parameters()},\n",
    "                              {'params': age_net.parameters()},\n",
    "                              {'params': ethnic_net.parameters()},\n",
    "                              {'params': relgion_net.parameters()},\n",
    "                              {'params': marital_net.parameters()},\n",
    "                              {'params': qual_net.parameters()}], lr=0.01)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.25)\n",
    "\n",
    "sex_net.apply(weights_init)\n",
    "age_net.apply(weights_init)\n",
    "ethnic_net.apply(weights_init)\n",
    "relgion_net.apply(weights_init)\n",
    "marital_net.apply(weights_init)\n",
    "qual_net.apply(weights_init)\n",
    "\n",
    "number_of_epochs = 200\n",
    "for epoch in range(number_of_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # generating and aggregating encoded population for sex, age, ethnicity\n",
    "    encoded_population = generate_population(input_tensor)\n",
    "    \n",
    "    categories_to_keep = ['sex', 'age', 'ethnicity']\n",
    "    kept_tensor = keep_categories(encoded_population, category_lengths, categories_to_keep)\n",
    "    aggregated_population1 = aggregate(kept_tensor, cross_table1, [sex_dict, age_dict, ethnic_dict])\n",
    "\n",
    "    categories_to_keep = ['sex', 'age', 'religion']\n",
    "    kept_tensor = keep_categories(encoded_population, category_lengths, categories_to_keep)\n",
    "    aggregated_population2 = aggregate(kept_tensor, cross_table2, [sex_dict, age_dict, religion_dict])\n",
    "\n",
    "    categories_to_keep = ['sex', 'age', 'marital']\n",
    "    kept_tensor = keep_categories(encoded_population, category_lengths, categories_to_keep)\n",
    "    aggregated_population3 = aggregate(kept_tensor, cross_table3, [sex_dict, age_dict, marital_dict])\n",
    "\n",
    "    categories_to_keep = ['sex', 'age', 'qual']\n",
    "    kept_tensor = keep_categories(encoded_population, category_lengths, categories_to_keep)\n",
    "    aggregated_population4 = aggregate(kept_tensor, cross_table4, [sex_dict, age_dict, qual_dict])\n",
    "    \n",
    "    loss = combined_rmse_loss(aggregated_population1,\n",
    "                              aggregated_population2,\n",
    "                              aggregated_population3,\n",
    "                              aggregated_population4,\n",
    "                              cross_table_tensor1,\n",
    "                              cross_table_tensor2,\n",
    "                              cross_table_tensor3,\n",
    "                              cross_table_tensor4)\n",
    "\n",
    "    accuracy1 = rmse_accuracy(aggregated_population1, cross_table_tensor1)\n",
    "    accuracy2 = rmse_accuracy(aggregated_population2, cross_table_tensor2)\n",
    "    accuracy3 = rmse_accuracy(aggregated_population3, cross_table_tensor3)\n",
    "    accuracy4 = rmse_accuracy(aggregated_population4, cross_table_tensor4)\n",
    "    accuracy = (accuracy1 + accuracy2 + accuracy3 + accuracy4) / 4\n",
    "    \n",
    "    loss_history.append(loss)\n",
    "    accuracy_history.append(accuracy)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}, Accuracy: {accuracy}\")\n",
    "        \n",
    "aggregated_population1 = aggregated_population1.round().long().cuda()\n",
    "aggregated_population2 = aggregated_population2.round().long().cuda()\n",
    "aggregated_population3 = aggregated_population3.round().long().cuda()\n",
    "aggregated_population4 = aggregated_population4.round().long().cuda()\n",
    "\n",
    "plot(cross_table_tensor1, aggregated_population1, cross_table1, 'Age-Sex-Ethnicity')\n",
    "plot(cross_table_tensor2, aggregated_population2, cross_table2, 'Age-Sex-Religion')\n",
    "plot(cross_table_tensor3, aggregated_population3, cross_table3, 'Age-Sex-MaritalStatus')\n",
    "plot(cross_table_tensor4, aggregated_population4, cross_table4, 'Age-Sex-Qualification')\n",
    "\n",
    "loss_history = [tensor.to('cpu').item() for tensor in loss_history]\n",
    "accuracy_history = [tensor for tensor in accuracy_history]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(len(loss_history)), loss_history, label='Training Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(len(accuracy_history)), accuracy_history, label='Training Accuracy')\n",
    "plt.title('Training Accuracy Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "records = decode_tensor(encoded_population, [sex_dict, age_dict, ethnic_dict, religion_dict, marital_dict, qual_dict])\n",
    "df = pd.DataFrame(records, columns=['sex', 'age', 'ethnicity', 'religion', 'marital', 'qualification'])\n",
    "age_categories_to_single = [\"0_4\", \"5_7\", \"8_9\", \"10_14\", \"15\"]\n",
    "df.loc[df['age'].isin(age_categories_to_single), 'marital'] = 'Single'\n",
    "df.loc[df['age'].isin(age_categories_to_single), 'qualification'] = 'no'\n",
    "df.to_csv('synthetic_population.csv', index=False)\n",
    "\n",
    "# recording execution end time\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "\n",
    "# converting the recordind time to hours, minutes, and seconds\n",
    "hours = int(duration // 3600)\n",
    "minutes = int((duration % 3600) // 60)\n",
    "seconds = duration % 60\n",
    "print(f\"Duration: {hours} hours, {minutes} minutes, {seconds:.2f} seconds\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:45:31.539529Z",
     "iopub.execute_input": "2024-03-14T12:45:31.539918Z",
     "iopub.status.idle": "2024-03-14T12:48:03.357812Z",
     "shell.execute_reply.started": "2024-03-14T12:45:31.539888Z",
     "shell.execute_reply": "2024-03-14T12:48:03.356766Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "file_path = '/kaggle/working/synthetic_population.csv' # loading the synthetic_population CSV file\n",
    "persons_df = pd.read_csv(file_path) # saving the loaded csv file to a pandas dataframe\n",
    "\n",
    "persons_df['Person_ID'] = range(1, len(persons_df) + 1) # assigning a person ID to each row"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:48:03.359493Z",
     "iopub.execute_input": "2024-03-14T12:48:03.359829Z",
     "iopub.status.idle": "2024-03-14T12:48:03.376406Z",
     "shell.execute_reply.started": "2024-03-14T12:48:03.359801Z",
     "shell.execute_reply": "2024-03-14T12:48:03.375621Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "area = 'E02005924'\n",
    "num_households = ID.get_HH_com_total(ID.HHcomdf, area)\n",
    "composition_counts = ID.getHHcomdictionary(ID.HHcomdf, area)\n",
    "hh_size_dist_org = ID.getdictionary(ID.HHsizedf, area)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:48:03.377590Z",
     "iopub.execute_input": "2024-03-14T12:48:03.377902Z",
     "iopub.status.idle": "2024-03-14T12:48:03.391859Z",
     "shell.execute_reply.started": "2024-03-14T12:48:03.377878Z",
     "shell.execute_reply": "2024-03-14T12:48:03.390819Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "households_df = pd.DataFrame(index=range(1, num_households + 1), columns=['Household_ID', 'Composition', 'Assigned_Persons'])\n",
    "for index, row in households_df.iterrows():\n",
    "    households_df.at[index, 'Assigned_Persons'] = []\n",
    "households_df['Household_ID'] = [str(i) for i in range(1, num_households + 1)]\n",
    "\n",
    "assert sum(composition_counts.values()) == num_households, \"Total rows should be equal to the number of households\"\n",
    "\n",
    "households_df['Composition'] = ''\n",
    "# populating the position' column based on counts\n",
    "current_row = 1\n",
    "for composition, count in composition_counts.items():\n",
    "    households_df.loc[current_row:current_row + count - 1, 'Composition'] = composition\n",
    "    current_row += count\n",
    "    \n",
    "composition_counts = households_df['Composition'].value_counts()\n",
    "print(composition_counts)\n",
    "print()\n",
    "print(composition_counts.sum())\n",
    "print()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:48:14.981093Z",
     "iopub.execute_input": "2024-03-14T12:48:14.981721Z",
     "iopub.status.idle": "2024-03-14T12:48:15.304840Z",
     "shell.execute_reply.started": "2024-03-14T12:48:14.981688Z",
     "shell.execute_reply": "2024-03-14T12:48:15.303837Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(households_df.head())\n",
    "print()\n",
    "print(households_df.tail())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:48:19.302970Z",
     "iopub.execute_input": "2024-03-14T12:48:19.303330Z",
     "iopub.status.idle": "2024-03-14T12:48:19.314305Z",
     "shell.execute_reply.started": "2024-03-14T12:48:19.303302Z",
     "shell.execute_reply": "2024-03-14T12:48:19.313356Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "order = ['1PA', '1PE', '1FM-0C', '1FM-1C', '1FC-0C', '1FC-1C', '1FL-1C', '1H-1C', '1FE', '1FM-nC', '1FM-nA', '1FC-nC', '1FC-nA', '1FL-nC', '1FL-nA', '1H-nC', '1H-nA', '1H-nE']\n",
    "households_df['Composition'] = pd.Categorical(households_df['Composition'], categories=order, ordered=True)\n",
    "households_df = households_df.sort_values('Composition')\n",
    "print(households_df)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:48:21.242503Z",
     "iopub.execute_input": "2024-03-14T12:48:21.242910Z",
     "iopub.status.idle": "2024-03-14T12:48:21.257425Z",
     "shell.execute_reply.started": "2024-03-14T12:48:21.242878Z",
     "shell.execute_reply": "2024-03-14T12:48:21.256382Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "nk = '8'\n",
    "ok = '8+'\n",
    "hh_size_dist_org[nk] = hh_size_dist_org[ok]\n",
    "del hh_size_dist_org[ok]\n",
    "\n",
    "values_size_org, weights_size_org = zip(*hh_size_dist_org.items())\n",
    "rk = ['1']\n",
    "household_size_dist = {key: value for key, value in hh_size_dist_org.items() if key not in rk}\n",
    "values_size, weights_size = zip(*household_size_dist.items())\n",
    "rk = ['1', '2']\n",
    "household_size_dist_na = {key: value for key, value in hh_size_dist_org.items() if key not in rk}\n",
    "values_size_na, weights_size_na = zip(*household_size_dist_na.items())\n",
    "rk = ['1', '2', '3']\n",
    "household_size_dist_nc = {key: value for key, value in hh_size_dist_org.items() if key not in rk}\n",
    "values_size_nc, weights_size_nc = zip(*household_size_dist_nc.items())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:48:24.578091Z",
     "iopub.execute_input": "2024-03-14T12:48:24.578843Z",
     "iopub.status.idle": "2024-03-14T12:48:24.586574Z",
     "shell.execute_reply.started": "2024-03-14T12:48:24.578809Z",
     "shell.execute_reply": "2024-03-14T12:48:24.585635Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(hh_size_dist_org)\n",
    "print(household_size_dist)\n",
    "print(household_size_dist_na)\n",
    "print(household_size_dist_nc)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:48:25.893124Z",
     "iopub.execute_input": "2024-03-14T12:48:25.893794Z",
     "iopub.status.idle": "2024-03-14T12:48:25.898992Z",
     "shell.execute_reply.started": "2024-03-14T12:48:25.893762Z",
     "shell.execute_reply": "2024-03-14T12:48:25.898001Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# individuals are in persons_df\n",
    "# households are in households_df\n",
    "\n",
    "child_ages = [\"0_4\", \"5_7\", \"8_9\", \"10_14\", \"15\"]\n",
    "adult_ages = [\"16_17\", \"18_19\", \"20_24\", \"25_29\", \"30_34\", \"35_39\", \"40_44\", \"45_49\", \"50_54\", \"55_59\", \"60_64\"]\n",
    "elder_ages = [\"65_69\", \"70_74\", \"75_79\", \"80_84\", \"85+\"]\n",
    "\n",
    "inter_ethnic_ratio = 0.1\n",
    "inter_rel_ratio = 0.015\n",
    "\n",
    "# recording execution start time\n",
    "start = time.time()\n",
    "\n",
    "def assign_individuals(row):\n",
    "    \n",
    "    random_number = random.random()\n",
    "    \n",
    "    # Composition # 1\n",
    "    # composition '1PE' One person: Pensioner (person who is above 65)\n",
    "    if row['Composition'] == '1PE':\n",
    "        # Filter individuals dataframe based on age category and sample one person\n",
    "        eligible_individuals = persons_df[\n",
    "            (persons_df['age'].isin(elder_ages))\n",
    "        ]\n",
    "\n",
    "        if not eligible_individuals.empty:\n",
    "            sampled_person = eligible_individuals.sample(1)\n",
    "            Person_ID = sampled_person['Person_ID'].values[0]\n",
    "\n",
    "            # Update the assigned_persons column in the households dataframe\n",
    "            row['Assigned_Persons'].append(Person_ID)\n",
    "\n",
    "            # Remove the sampled person from individuals dataframe\n",
    "            persons_df.drop(persons_df[persons_df['Person_ID'] == Person_ID].index, inplace=True)\n",
    "\n",
    "    # Composition # 2\n",
    "    # composition '1PA' One person: Other (a single person who is above 18 and below 65)\n",
    "    if row['Composition'] == '1PA':\n",
    "        # Filter individuals dataframe based on age category and sample one person\n",
    "        eligible_individuals = persons_df[\n",
    "            (persons_df['age'].isin(adult_ages))\n",
    "        ]\n",
    "\n",
    "        if not eligible_individuals.empty:\n",
    "            sampled_person = eligible_individuals.sample(1)\n",
    "            Person_ID = sampled_person['Person_ID'].values[0]\n",
    "\n",
    "            # Update the assigned_persons column in the households dataframe\n",
    "            row['Assigned_Persons'].append(Person_ID)\n",
    "\n",
    "            # Remove the sampled person from individuals dataframe\n",
    "            persons_df.drop(persons_df[persons_df['Person_ID'] == Person_ID].index, inplace=True)\n",
    "            \n",
    "    # Composition # 3\n",
    "    # composition '1FM-0C' One family: Married Couple: No children\n",
    "    if row['Composition'] == '1FM-0C':\n",
    "        # Filter individuals dataframe based on criteria and sample one male person\n",
    "        eligible_male_individuals = persons_df[\n",
    "            (persons_df['marital'] == 'Married') &\n",
    "            (persons_df['sex'] == 'M') &\n",
    "            (~persons_df['age'].isin(child_ages))\n",
    "        ]\n",
    "\n",
    "        # Sample one male person\n",
    "        if not eligible_male_individuals.empty:\n",
    "            male_person = eligible_male_individuals.sample(1)\n",
    "\n",
    "            # Get the male person's ethnicity and religion\n",
    "            male_ethnicity = male_person['ethnicity'].values[0]\n",
    "            male_religion = male_person['religion'].values[0]\n",
    "            \n",
    "            if random_number < inter_ethnic_ratio:\n",
    "                if random_number < inter_rel_ratio:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['marital'] == 'Married') &\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] != male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "                else:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['marital'] == 'Married') &\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            else:\n",
    "                eligible_female_individuals = persons_df[\n",
    "                        (persons_df['marital'] == 'Married') &\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "\n",
    "            # Sample one female person\n",
    "            if not eligible_female_individuals.empty:\n",
    "                female_person = eligible_female_individuals.sample(1)\n",
    "\n",
    "                male_person_id = male_person['Person_ID'].values[0]\n",
    "                female_person_id = female_person['Person_ID'].values[0]\n",
    "\n",
    "                row['Assigned_Persons'].extend([male_person_id, female_person_id])\n",
    "\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin([male_person_id, female_person_id])].index, inplace=True)\n",
    "                    \n",
    "    # Composition # 4\n",
    "    # composition '1FM-1C' One family: Married Couple: 1 dependent child\n",
    "    if row['Composition'] == '1FM-1C':\n",
    "        # Filter individuals dataframe based on criteria and sample one male person\n",
    "        eligible_male_individuals = persons_df[\n",
    "            (persons_df['marital'] == 'Married') &\n",
    "            (persons_df['sex'] == 'M') &\n",
    "            (~persons_df['age'].isin(child_ages))\n",
    "        ]\n",
    "\n",
    "        # Sample one male person\n",
    "        if not eligible_male_individuals.empty:\n",
    "            male_person = eligible_male_individuals.sample(1)\n",
    "\n",
    "            # Get the male person's ethnicity and religion\n",
    "            male_ethnicity = male_person['ethnicity'].values[0]\n",
    "            male_religion = male_person['religion'].values[0]\n",
    "\n",
    "            if random_number < inter_ethnic_ratio:\n",
    "                if random_number < inter_rel_ratio:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['marital'] == 'Married') &\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] != male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "                else:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['marital'] == 'Married') &\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            else:\n",
    "                eligible_female_individuals = persons_df[\n",
    "                        (persons_df['marital'] == 'Married') &\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            \n",
    "            eligible_children = persons_df[\n",
    "                (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                (persons_df['religion'] == male_religion) &\n",
    "                (persons_df['age'].isin(child_ages))\n",
    "            ]\n",
    "\n",
    "            # Sample one female person\n",
    "            if not eligible_female_individuals.empty:\n",
    "                female_person = eligible_female_individuals.sample(1)\n",
    "                \n",
    "                if not eligible_children.empty:\n",
    "                    child = eligible_children.sample(1)\n",
    "\n",
    "                    # Get Person_IDs\n",
    "                    male_person_id = male_person['Person_ID'].values[0]\n",
    "                    female_person_id = female_person['Person_ID'].values[0]\n",
    "                    child_id = child['Person_ID'].values[0]\n",
    "\n",
    "                    row['Assigned_Persons'].extend([male_person_id, female_person_id, child_id])\n",
    "\n",
    "                    persons_df.drop(persons_df[persons_df['Person_ID'].isin([male_person_id, female_person_id, child_id])].index, inplace=True)\n",
    "        \n",
    "    # Composition # 5\n",
    "    # composition '1FC-0C' One family: Cohabiting Couple: No children\n",
    "    if row['Composition'] == '1FC-0C':\n",
    "        # Filter individuals dataframe based on criteria and sample one male person\n",
    "        eligible_male_individuals = persons_df[\n",
    "            (persons_df['sex'] == 'M') &\n",
    "            (~persons_df['age'].isin(child_ages))\n",
    "        ]\n",
    "\n",
    "        # Sample one male person\n",
    "        if not eligible_male_individuals.empty:\n",
    "            male_person = eligible_male_individuals.sample(1)\n",
    "\n",
    "            # Get the male person's ethnicity and religion\n",
    "            male_ethnicity = male_person['ethnicity'].values[0]\n",
    "            male_religion = male_person['religion'].values[0]\n",
    "            \n",
    "            male_person_id = male_person['Person_ID'].values[0]\n",
    "            row['Assigned_Persons'].extend([male_person_id])\n",
    "            persons_df.drop(persons_df[persons_df['Person_ID'].isin([male_person_id])].index, inplace=True)\n",
    "\n",
    "            # Filter eligible females based on the same ethnicity and religion\n",
    "            if random_number < inter_ethnic_ratio:\n",
    "                if random_number < inter_rel_ratio:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] != male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "                else:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            else:\n",
    "                eligible_female_individuals = persons_df[\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "\n",
    "            # Sample one female person\n",
    "            if not eligible_female_individuals.empty:\n",
    "                female_person = eligible_female_individuals.sample(1)\n",
    "\n",
    "                female_person_id = female_person['Person_ID'].values[0]\n",
    "                row['Assigned_Persons'].extend([female_person_id])\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin([female_person_id])].index, inplace=True)\n",
    "    \n",
    "    # Composition # 6\n",
    "    # composition '1FC-1C' One family: Cohabiting Couple: 1 dependent child\n",
    "    if row['Composition'] == '1FC-1C':\n",
    "        # Filter individuals dataframe based on criteria and sample one male person\n",
    "        eligible_male_individuals = persons_df[\n",
    "            (persons_df['sex'] == 'M') &\n",
    "            (~persons_df['age'].isin(child_ages))\n",
    "        ]\n",
    "\n",
    "        # Sample one male person\n",
    "        if not eligible_male_individuals.empty:\n",
    "            male_person = eligible_male_individuals.sample(1)\n",
    "\n",
    "            # Get the male person's ethnicity and religion\n",
    "            male_ethnicity = male_person['ethnicity'].values[0]\n",
    "            male_religion = male_person['religion'].values[0]\n",
    "            \n",
    "            male_person_id = male_person['Person_ID'].values[0]\n",
    "            row['Assigned_Persons'].extend([male_person_id])\n",
    "            persons_df.drop(persons_df[persons_df['Person_ID'].isin([male_person_id])].index, inplace=True)\n",
    "\n",
    "            if random_number < inter_ethnic_ratio:\n",
    "                if random_number < inter_rel_ratio:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] != male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "                else:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            else:\n",
    "                eligible_female_individuals = persons_df[\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            \n",
    "            eligible_children = persons_df[\n",
    "                (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                (persons_df['religion'] == male_religion) &\n",
    "                (persons_df['age'].isin(child_ages))\n",
    "            ]\n",
    "\n",
    "            # Sample one female person\n",
    "            if not eligible_female_individuals.empty:\n",
    "                female_person = eligible_female_individuals.sample(1)\n",
    "                female_person_id = female_person['Person_ID'].values[0]\n",
    "                row['Assigned_Persons'].extend([female_person_id])\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin([female_person_id])].index, inplace=True)\n",
    "                \n",
    "                if not eligible_children.empty:\n",
    "                    child = eligible_children.sample(1)\n",
    "\n",
    "                    child_id = child['Person_ID'].values[0]\n",
    "                    row['Assigned_Persons'].extend([child_id])\n",
    "                    persons_df.drop(persons_df[persons_df['Person_ID'].isin([child_id])].index, inplace=True)\n",
    "                    \n",
    "    # Composition # 7\n",
    "    # composition '1FL-1C' One family: Lone Parent: 1 dependent child\n",
    "    if row['Composition'] == '1FL-1C':\n",
    "        # Filter individuals dataframe based on criteria and sample one male person\n",
    "        eligible_parent = persons_df[\n",
    "            (persons_df['marital'] != 'Married') &\n",
    "            (~persons_df['age'].isin(child_ages))\n",
    "        ]\n",
    "\n",
    "        # Sample one parent\n",
    "        if not eligible_parent.empty:\n",
    "            parent = eligible_parent.sample(1)\n",
    "\n",
    "            # Get the male person's ethnicity and religion\n",
    "            parent_ethnicity = parent['ethnicity'].values[0]\n",
    "            parent_religion = parent['religion'].values[0]\n",
    "            \n",
    "            eligible_children = persons_df[\n",
    "                (persons_df['ethnicity'] == parent_ethnicity) &\n",
    "                (persons_df['religion'] == parent_religion) &\n",
    "                (persons_df['age'].isin(child_ages))\n",
    "            ]\n",
    "\n",
    "            if not eligible_children.empty:\n",
    "                child = eligible_children.sample(1)\n",
    "\n",
    "                # Get Person_IDs\n",
    "                parent_id = parent['Person_ID'].values[0]\n",
    "                child_id = child['Person_ID'].values[0]\n",
    "\n",
    "                row['Assigned_Persons'].extend([parent_id, child_id])\n",
    "\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin([parent_id, child_id])].index, inplace=True)\n",
    "    \n",
    "    # Composition # 8\n",
    "    # composition '1FE' One family: All pensioner (a family consisting of persons all above 65)\n",
    "    if row['Composition'] == '1FE':\n",
    "        # specifying the number of individuals to sample according to distribution of household sizes        \n",
    "        n = int(random.choices(values_size, weights=weights_size)[0]) - 1\n",
    "\n",
    "        eligible_individuals = persons_df[\n",
    "            (persons_df['age'].isin(elder_ages))\n",
    "        ]\n",
    "        \n",
    "        if not eligible_individuals.empty:\n",
    "            first_person = eligible_individuals.sample(1)\n",
    "            \n",
    "            first_person_id = first_person['Person_ID'].values[0]\n",
    "            row['Assigned_Persons'].append(first_person_id)\n",
    "            persons_df.drop(persons_df[persons_df['Person_ID'].isin([first_person_id])].index, inplace=True)\n",
    "            \n",
    "            first_person_ethnicity = first_person['ethnicity'].values[0]\n",
    "            first_person_religion = first_person['religion'].values[0]\n",
    "            \n",
    "            other_eligible_persons = persons_df[\n",
    "                (persons_df['ethnicity'] == first_person_ethnicity) &\n",
    "                (persons_df['religion'] == first_person_religion) &\n",
    "                (persons_df['age'].isin(elder_ages))\n",
    "            ]\n",
    "            \n",
    "            if len(other_eligible_persons) >= n:\n",
    "                sampled_elders = other_eligible_persons.sample(n)\n",
    "                sampled_elders_ids = sampled_elders['Person_ID'].tolist()\n",
    "\n",
    "                row['Assigned_Persons'].extend(sampled_elders_ids)\n",
    "\n",
    "                # Remove the sampled persons from the individuals dataframe\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin(sampled_elders['Person_ID'])].index, inplace=True)\n",
    "                \n",
    "    # Composition # 9\n",
    "    # composition '1FM-nC' One family: Married Couple: 2 or more dependent child\n",
    "    if row['Composition'] == '1FM-nC':\n",
    "        n = int(random.choices(values_size_nc, weights=weights_size_nc)[0]) - 2\n",
    "        \n",
    "        # Filter individuals dataframe based on criteria and sample one male person\n",
    "        eligible_male_individuals = persons_df[\n",
    "            (persons_df['marital'] == 'Married') &\n",
    "            (persons_df['sex'] == 'M') &\n",
    "            (~persons_df['age'].isin(child_ages))\n",
    "        ]\n",
    "\n",
    "        # Sample one male person\n",
    "        if not eligible_male_individuals.empty:\n",
    "            male_person = eligible_male_individuals.sample(1)\n",
    "            male_person_id = male_person['Person_ID'].values[0]\n",
    "            row['Assigned_Persons'].extend([male_person_id])\n",
    "            persons_df.drop(persons_df[persons_df['Person_ID'].isin([male_person_id])].index, inplace=True)\n",
    "\n",
    "            # Get the male person's ethnicity and religion\n",
    "            male_ethnicity = male_person['ethnicity'].values[0]\n",
    "            male_religion = male_person['religion'].values[0]\n",
    "\n",
    "            if random_number < inter_ethnic_ratio:\n",
    "                if random_number < inter_rel_ratio:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['marital'] == 'Married') &\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] != male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "                else:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['marital'] == 'Married') &\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            else:\n",
    "                eligible_female_individuals = persons_df[\n",
    "                        (persons_df['marital'] == 'Married') &\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            \n",
    "            eligible_children = persons_df[\n",
    "                (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                (persons_df['religion'] == male_religion) &\n",
    "                (persons_df['age'].isin(child_ages))\n",
    "            ]\n",
    "\n",
    "            # Sample one female person\n",
    "            if not eligible_female_individuals.empty:\n",
    "                female_person = eligible_female_individuals.sample(1)\n",
    "                female_person_id = female_person['Person_ID'].values[0]\n",
    "                row['Assigned_Persons'].extend([female_person_id])\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin([female_person_id])].index, inplace=True)\n",
    "                \n",
    "                if len(eligible_children) >= n:\n",
    "                    sampled_children = eligible_children.sample(n)\n",
    "                    sampled_children_ids = sampled_children['Person_ID'].tolist()                    \n",
    "                    row['Assigned_Persons'].extend(sampled_children_ids)                    \n",
    "                    persons_df.drop(persons_df[persons_df['Person_ID'].isin(sampled_children['Person_ID'])].index, inplace=True)\n",
    "                    \n",
    "    # Composition # 10\n",
    "    # composition '1FC-nC' One family: Cohabiting Couple: 2 or more dependent child\n",
    "    if row['Composition'] == '1FC-nC':\n",
    "        n = int(random.choices(values_size_nc, weights=weights_size_nc)[0]) - 2\n",
    "        \n",
    "        # Filter individuals dataframe based on criteria and sample one male person\n",
    "        eligible_male_individuals = persons_df[\n",
    "            (persons_df['sex'] == 'M') &\n",
    "            (~persons_df['age'].isin(child_ages))\n",
    "        ]\n",
    "\n",
    "        # Sample one male person\n",
    "        if not eligible_male_individuals.empty:\n",
    "            male_person = eligible_male_individuals.sample(1)\n",
    "            male_person_id = male_person['Person_ID'].values[0]\n",
    "            row['Assigned_Persons'].extend([male_person_id])\n",
    "            persons_df.drop(persons_df[persons_df['Person_ID'].isin([male_person_id])].index, inplace=True)\n",
    "\n",
    "            # Get the male person's ethnicity and religion\n",
    "            male_ethnicity = male_person['ethnicity'].values[0]\n",
    "            male_religion = male_person['religion'].values[0]\n",
    "\n",
    "            if random_number < inter_ethnic_ratio:\n",
    "                if random_number < inter_rel_ratio:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] != male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "                else:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            else:\n",
    "                eligible_female_individuals = persons_df[\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            \n",
    "            eligible_children = persons_df[\n",
    "                (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                (persons_df['religion'] == male_religion) &\n",
    "                (persons_df['age'].isin(child_ages))\n",
    "            ]\n",
    "\n",
    "            # Sample one female person\n",
    "            if not eligible_female_individuals.empty:\n",
    "                female_person = eligible_female_individuals.sample(1)\n",
    "                female_person_id = female_person['Person_ID'].values[0]\n",
    "                row['Assigned_Persons'].extend([female_person_id])\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin([female_person_id])].index, inplace=True)\n",
    "                \n",
    "                if len(eligible_children) >= n:\n",
    "                    sampled_children = eligible_children.sample(n)\n",
    "                    sampled_children_ids = sampled_children['Person_ID'].tolist()\n",
    "                    row['Assigned_Persons'].extend(sampled_children_ids)                   \n",
    "                    persons_df.drop(persons_df[persons_df['Person_ID'].isin(sampled_children['Person_ID'])].index, inplace=True)\n",
    "                    \n",
    "    # Composition # 11\n",
    "    # composition '1FL-nC' One family: Lone Parent: 2 or more dependent child\n",
    "    if row['Composition'] == '1FL-nC':\n",
    "        n = int(random.choices(values_size_nc, weights=weights_size_nc)[0]) - 2\n",
    "        \n",
    "        # Filter individuals dataframe based on criteria and sample one male person\n",
    "        eligible_parent = persons_df[\n",
    "            (persons_df['marital'] != 'Married') &\n",
    "            (~persons_df['age'].isin(child_ages))\n",
    "        ]\n",
    "\n",
    "        # sample one parent\n",
    "        if not eligible_parent.empty:\n",
    "            parent = eligible_parent.sample(1)\n",
    "\n",
    "            # Get the male person's ethnicity and religion\n",
    "            parent_ethnicity = parent['ethnicity'].values[0]\n",
    "            parent_religion = parent['religion'].values[0]\n",
    "            \n",
    "            eligible_children = persons_df[\n",
    "                (persons_df['ethnicity'] == parent_ethnicity) &\n",
    "                (persons_df['religion'] == parent_religion) &\n",
    "                (persons_df['age'].isin(child_ages))\n",
    "            ]\n",
    "\n",
    "            if len(eligible_children) >= n:\n",
    "                sampled_children = eligible_children.sample(n)\n",
    "                sampled_children_ids = sampled_children['Person_ID'].tolist()\n",
    "\n",
    "                # Get Person_IDs\n",
    "                parent_id = parent['Person_ID'].values[0]\n",
    "\n",
    "                row['Assigned_Persons'].extend([parent_id])\n",
    "                row['Assigned_Persons'].extend(sampled_children_ids)\n",
    "\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin([parent_id])].index, inplace=True)\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin(sampled_children['Person_ID'])].index, inplace=True)\n",
    "                \n",
    "    # Composition # 12\n",
    "    # composition '1FM-nA' One family: Married Couple: all children non-dependent\n",
    "    if row['Composition'] == '1FM-nA':\n",
    "        n = int(random.choices(values_size_na, weights=weights_size_na)[0]) - 2\n",
    "        \n",
    "        # Filter individuals dataframe based on criteria and sample one male person\n",
    "        eligible_male_individuals = persons_df[\n",
    "            (persons_df['marital'] == 'Married') &\n",
    "            (persons_df['sex'] == 'M') &\n",
    "            (~persons_df['age'].isin(child_ages))\n",
    "        ]\n",
    "\n",
    "        # Sample one male person\n",
    "        if not eligible_male_individuals.empty:\n",
    "            male_person = eligible_male_individuals.sample(1)\n",
    "\n",
    "            # Get the male person's ethnicity and religion\n",
    "            male_ethnicity = male_person['ethnicity'].values[0]\n",
    "            male_religion = male_person['religion'].values[0]\n",
    "            \n",
    "            male_person_id = male_person['Person_ID'].values[0]\n",
    "            row['Assigned_Persons'].extend([male_person_id])\n",
    "            persons_df.drop(persons_df[persons_df['Person_ID'].isin([male_person_id])].index, inplace=True)\n",
    "\n",
    "            if random_number < inter_ethnic_ratio:\n",
    "                if random_number < inter_rel_ratio:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['marital'] == 'Married') &\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] != male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "                else:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['marital'] == 'Married') &\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            else:\n",
    "                eligible_female_individuals = persons_df[\n",
    "                        (persons_df['marital'] == 'Married') &\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            \n",
    "            eligible_children = persons_df[\n",
    "                (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                (persons_df['religion'] == male_religion) &\n",
    "                (persons_df['age'].isin(adult_ages))\n",
    "            ]\n",
    "\n",
    "            # Sample one female person\n",
    "            if not eligible_female_individuals.empty:\n",
    "                female_person = eligible_female_individuals.sample(1)\n",
    "                female_person_id = female_person['Person_ID'].values[0]\n",
    "                row['Assigned_Persons'].extend([female_person_id])\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin([female_person_id])].index, inplace=True)\n",
    "                \n",
    "                if len(eligible_children) >= n:\n",
    "                    sampled_children = eligible_children.sample(n)\n",
    "                    sampled_children_ids = sampled_children['Person_ID'].tolist()\n",
    "                    row['Assigned_Persons'].extend(sampled_children_ids)                    \n",
    "                    persons_df.drop(persons_df[persons_df['Person_ID'].isin(sampled_children['Person_ID'])].index, inplace=True)\n",
    "                    \n",
    "    # Composition # 13\n",
    "    # composition '1FC-nA' One family: Cohabiting Couple: all children non-dependent\n",
    "    if row['Composition'] == '1FC-nA':\n",
    "        n = int(random.choices(values_size_na, weights=weights_size_na)[0]) - 2\n",
    "        \n",
    "        # Filter individuals dataframe based on criteria and sample one male person\n",
    "        eligible_male_individuals = persons_df[\n",
    "            (persons_df['sex'] == 'M') &\n",
    "            (~persons_df['age'].isin(child_ages))\n",
    "        ]\n",
    "\n",
    "        # Sample one male person\n",
    "        if not eligible_male_individuals.empty:\n",
    "            male_person = eligible_male_individuals.sample(1)\n",
    "\n",
    "            # Get the male person's ethnicity and religion\n",
    "            male_ethnicity = male_person['ethnicity'].values[0]\n",
    "            male_religion = male_person['religion'].values[0]\n",
    "            \n",
    "            male_person_id = male_person['Person_ID'].values[0]\n",
    "            row['Assigned_Persons'].extend([male_person_id])\n",
    "            persons_df.drop(persons_df[persons_df['Person_ID'].isin([male_person_id])].index, inplace=True)            \n",
    "\n",
    "            if random_number < inter_ethnic_ratio:\n",
    "                if random_number < inter_rel_ratio:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] != male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "                else:\n",
    "                    eligible_female_individuals = persons_df[\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] != male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            else:\n",
    "                eligible_female_individuals = persons_df[\n",
    "                        (persons_df['sex'] == 'F') &\n",
    "                        (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                        (persons_df['religion'] == male_religion) &\n",
    "                        (~persons_df['age'].isin(child_ages))\n",
    "                    ]\n",
    "            \n",
    "            eligible_children = persons_df[\n",
    "                (persons_df['ethnicity'] == male_ethnicity) &\n",
    "                (persons_df['religion'] == male_religion) &\n",
    "                (persons_df['age'].isin(adult_ages))\n",
    "            ]\n",
    "\n",
    "            # Sample one female person\n",
    "            if not eligible_female_individuals.empty:\n",
    "                female_person = eligible_female_individuals.sample(1)\n",
    "                female_person_id = female_person['Person_ID'].values[0]         \n",
    "                row['Assigned_Persons'].extend([female_person_id])\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin([female_person_id])].index, inplace=True)                \n",
    "                \n",
    "                if len(eligible_children) >= n:\n",
    "                    sampled_children = eligible_children.sample(n)\n",
    "                    sampled_children_ids = sampled_children['Person_ID'].tolist()\n",
    "                    row['Assigned_Persons'].extend(sampled_children_ids)                    \n",
    "                    persons_df.drop(persons_df[persons_df['Person_ID'].isin(sampled_children['Person_ID'])].index, inplace=True)\n",
    "                    \n",
    "    # Composition # 14\n",
    "    # composition '1FL-nA' One family: Lone parent: all children non-dependent\n",
    "    if row['Composition'] == '1FL-nA':\n",
    "        n = int(random.choices(values_size_na, weights=weights_size_na)[0]) - 2\n",
    "        \n",
    "        # filtering individuals dataframe based on criteria and sampling one male person\n",
    "        eligible_parent = persons_df[\n",
    "            (persons_df['marital'] != 'Married') &\n",
    "            (~persons_df['age'].isin(child_ages))\n",
    "        ]\n",
    "\n",
    "        # sampling one parent\n",
    "        if not eligible_parent.empty:\n",
    "            parent = eligible_parent.sample(1)\n",
    "\n",
    "            # getting the first person's ethnicity and religion\n",
    "            parent_ethnicity = parent['ethnicity'].values[0]\n",
    "            parent_religion = parent['religion'].values[0]\n",
    "            \n",
    "            eligible_children = persons_df[\n",
    "                (persons_df['ethnicity'] == parent_ethnicity) &\n",
    "                (persons_df['religion'] == parent_religion) &\n",
    "                (persons_df['age'].isin(adult_ages))\n",
    "            ]\n",
    "\n",
    "            if len(eligible_children) >= n:\n",
    "                sampled_children = eligible_children.sample(n)\n",
    "                sampled_children_ids = sampled_children['Person_ID'].tolist()\n",
    "\n",
    "                # Get Person_IDs\n",
    "                parent_id = parent['Person_ID'].values[0]\n",
    "\n",
    "                row['Assigned_Persons'].extend([parent_id])\n",
    "                row['Assigned_Persons'].extend(sampled_children_ids)\n",
    "\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin([parent_id])].index, inplace=True)\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin(sampled_children['Person_ID'])].index, inplace=True)\n",
    "                \n",
    "    # Composition # 15\n",
    "    # composition '1H-1C' Other households: With one dependent child\n",
    "    if row['Composition'] == '1H-1C':\n",
    "        # Filter individuals dataframe based on criteria and sample one male person\n",
    "        eligible_adults = persons_df[\n",
    "            (~persons_df['age'].isin(child_ages))\n",
    "        ]\n",
    "\n",
    "        # Sample one male person\n",
    "        if not eligible_adults.empty:\n",
    "            adult = eligible_adults.sample(1)\n",
    "\n",
    "            # Get the male person's ethnicity and religion\n",
    "            adult_ethnicity = adult['ethnicity'].values[0]\n",
    "            adult_religion = adult['religion'].values[0]\n",
    "            \n",
    "            eligible_children = persons_df[\n",
    "                (persons_df['ethnicity'] == adult_ethnicity) &\n",
    "                (persons_df['religion'] == adult_religion) &\n",
    "                (persons_df['age'].isin(child_ages))\n",
    "            ]\n",
    "            \n",
    "            if not eligible_children.empty:\n",
    "                child = eligible_children.sample(1)\n",
    "\n",
    "                # Get Person_IDs\n",
    "                adult_id = adult['Person_ID'].values[0]\n",
    "                child_id = child['Person_ID'].values[0]\n",
    "\n",
    "                row['Assigned_Persons'].extend([adult_id, child_id])\n",
    "\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin([adult_id, child_id])].index, inplace=True)\n",
    "                \n",
    "    # Composition # 16\n",
    "    # composition '1H-nC' Other households: With two or more dependent children\n",
    "    \n",
    "    \n",
    "    if row['Composition'] == '1H-nC':\n",
    "        n = int(random.choices(values_size, weights=weights_size)[0]) - 1\n",
    "        \n",
    "        # Filter individuals dataframe based on criteria and sample one male person\n",
    "        eligible_adults = persons_df[\n",
    "            (~persons_df['age'].isin(child_ages))\n",
    "        ]\n",
    "\n",
    "        # Sample one male person\n",
    "        if not eligible_adults.empty:\n",
    "            adult = eligible_adults.sample(1)\n",
    "\n",
    "            # Get the male person's ethnicity and religion\n",
    "            adult_ethnicity = adult['ethnicity'].values[0]\n",
    "            adult_religion = adult['religion'].values[0]\n",
    "            \n",
    "            eligible_children = persons_df[\n",
    "                (persons_df['ethnicity'] == adult_ethnicity) &\n",
    "                (persons_df['religion'] == adult_religion) &\n",
    "                (persons_df['age'].isin(child_ages))\n",
    "            ]\n",
    "            \n",
    "            if len(eligible_children) >= n:\n",
    "                sampled_children = eligible_children.sample(n)\n",
    "                sampled_children_ids = sampled_children['Person_ID'].tolist()\n",
    "                adult_id = adult['Person_ID'].values[0]\n",
    "\n",
    "                row['Assigned_Persons'].extend([adult_id])\n",
    "                row['Assigned_Persons'].extend(sampled_children_ids)\n",
    "\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin([adult_id])].index, inplace=True)\n",
    "                persons_df.drop(persons_df[persons_df['Person_ID'].isin(sampled_children['Person_ID'])].index, inplace=True)\n",
    "                \n",
    "    # Composition # 17\n",
    "    # composition '1H-nA' Other households: All student\n",
    "    if row['Composition'] == '1H-nA':\n",
    "        n = int(random.choices(values_size_org, weights=weights_size_org)[0])\n",
    "        \n",
    "        eligible_members = persons_df[\n",
    "            (~persons_df['age'].isin(child_ages)) &\n",
    "            (persons_df['qualification'] != 'no')\n",
    "        ]\n",
    "\n",
    "        if len(eligible_members) >= n:\n",
    "            sampled_members = eligible_members.sample(n)\n",
    "            sampled_members_ids = sampled_members['Person_ID'].tolist()\n",
    "            \n",
    "            row['Assigned_Persons'].extend(sampled_members_ids)\n",
    "            \n",
    "            persons_df.drop(persons_df[persons_df['Person_ID'].isin(sampled_members['Person_ID'])].index, inplace=True)\n",
    "            \n",
    "    # Composition # 18\n",
    "    # composition '1H-nE' Other households: All pensioner\n",
    "    if row['Composition'] == '1H-nA':\n",
    "        n = int(random.choices(values_size_org, weights=weights_size_org)[0])\n",
    "        \n",
    "        eligible_members = persons_df[\n",
    "            (persons_df['age'].isin(elder_ages))\n",
    "        ]\n",
    "\n",
    "        if len(eligible_members) >= n:\n",
    "            sampled_members = eligible_members.sample(n)\n",
    "            sampled_members_ids = sampled_members['Person_ID'].tolist()\n",
    "            \n",
    "            row['Assigned_Persons'].extend(sampled_members_ids)\n",
    "            \n",
    "            persons_df.drop(persons_df[persons_df['Person_ID'].isin(sampled_members['Person_ID'])].index, inplace=True)\n",
    "            \n",
    "    return row\n",
    "\n",
    "# applying the assign_individuals function to each row in the households dataframe\n",
    "households_df = households_df.apply(assign_individuals, axis=1)\n",
    "\n",
    "# recording execution end time\n",
    "end = time.time()\n",
    "duration = end - start\n",
    "\n",
    "# converting the recordind time to hours, minutes, and seconds\n",
    "hours = int(duration // 3600)\n",
    "minutes = int((duration % 3600) // 60)\n",
    "seconds = duration % 60\n",
    "print(f\"Duration: {hours} hours, {minutes} minutes, {seconds:.2f} seconds\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:48:39.690010Z",
     "iopub.execute_input": "2024-03-14T12:48:39.690330Z",
     "iopub.status.idle": "2024-03-14T12:49:17.574946Z",
     "shell.execute_reply.started": "2024-03-14T12:48:39.690307Z",
     "shell.execute_reply": "2024-03-14T12:49:17.574008Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'households_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 811\u001B[0m\n\u001B[0;32m    808\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m row\n\u001B[0;32m    810\u001B[0m \u001B[38;5;66;03m# applying the assign_individuals function to each row in the households dataframe\u001B[39;00m\n\u001B[1;32m--> 811\u001B[0m households_df \u001B[38;5;241m=\u001B[39m \u001B[43mhouseholds_df\u001B[49m\u001B[38;5;241m.\u001B[39mapply(assign_individuals, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    813\u001B[0m \u001B[38;5;66;03m# recording execution end time\u001B[39;00m\n\u001B[0;32m    814\u001B[0m end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'households_df' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "empty_count = households_df['Assigned_Persons'].apply(lambda x: len(x) == 0).sum()\n",
    "non_empty_count = households_df['Assigned_Persons'].apply(lambda x: len(x) > 0).sum()\n",
    "\n",
    "print(f\"Rows with empty lists: {empty_count}\")\n",
    "print(f\"Rows with non-empty lists: {non_empty_count}\")\n",
    "ap = empty_count / (non_empty_count + empty_count) * 100\n",
    "uap = non_empty_count / (non_empty_count + empty_count) * 100\n",
    "print(f\"Aassigned Household Percentage: {ap}\")\n",
    "print(f\"Unassigned Household Percentage: {uap}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:49:17.576683Z",
     "iopub.execute_input": "2024-03-14T12:49:17.577027Z",
     "iopub.status.idle": "2024-03-14T12:49:17.587617Z",
     "shell.execute_reply.started": "2024-03-14T12:49:17.576996Z",
     "shell.execute_reply": "2024-03-14T12:49:17.586454Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "households_df = households_df.sample(frac=1).reset_index(drop=True)\n",
    "print(households_df.head())\n",
    "print()\n",
    "print(households_df.tail())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:49:17.588986Z",
     "iopub.execute_input": "2024-03-14T12:49:17.589308Z",
     "iopub.status.idle": "2024-03-14T12:49:17.613640Z",
     "shell.execute_reply.started": "2024-03-14T12:49:17.589280Z",
     "shell.execute_reply": "2024-03-14T12:49:17.612625Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "households_df.to_csv('households.csv', index=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T12:50:01.636428Z",
     "iopub.execute_input": "2024-03-14T12:50:01.637191Z",
     "iopub.status.idle": "2024-03-14T12:50:01.656550Z",
     "shell.execute_reply.started": "2024-03-14T12:50:01.637155Z",
     "shell.execute_reply": "2024-03-14T12:50:01.655618Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}